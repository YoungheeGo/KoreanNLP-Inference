{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "koBERT-lm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "17mPuTDt6vhTSGFJJeDcXZ3aEEcNVBFOG",
      "authorship_tag": "ABX9TyMYS5VqvafrQV212Fuan2zz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "646399107d1a430a801ae417fb1e2bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eb4cf5a6ec98416a960e16b425fbbf75",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_458160224e2d4d148a2c6392551dac44",
              "IPY_MODEL_2243391d21c14eb995d6328c0d6f2c17",
              "IPY_MODEL_5f8d2ace9853473dbf79b69f9b183740"
            ]
          }
        },
        "eb4cf5a6ec98416a960e16b425fbbf75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "458160224e2d4d148a2c6392551dac44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_98b2bea8376a4747ad5777e47823aa55",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_368100c081d24b04b7d050e414b26bb6"
          }
        },
        "2243391d21c14eb995d6328c0d6f2c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_966c67dba33743ceb608611d17ff7128",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 513,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 513,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cad9b92241c4477e87d822dd392c1604"
          }
        },
        "5f8d2ace9853473dbf79b69f9b183740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad1ff2b3f96346749a652689842822be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 513/513 [00:00&lt;00:00, 8.68kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3c9159ccd6a4b2a8d170d6f01b9b4d8"
          }
        },
        "98b2bea8376a4747ad5777e47823aa55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "368100c081d24b04b7d050e414b26bb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "966c67dba33743ceb608611d17ff7128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cad9b92241c4477e87d822dd392c1604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad1ff2b3f96346749a652689842822be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a3c9159ccd6a4b2a8d170d6f01b9b4d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fcde5e04cc34425faa75df386c848140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f9ecde7dee34a68b6bbfff095ffb8a7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5221ea0d43004660a12a18b463b8f078",
              "IPY_MODEL_5f00b29edba34a95b296f7d8a64e18df",
              "IPY_MODEL_f513dfab11b04d92b7e772b68afa28dc"
            ]
          }
        },
        "2f9ecde7dee34a68b6bbfff095ffb8a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5221ea0d43004660a12a18b463b8f078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb96c91476c843848f4fe29561abf0e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c211cbbacf4e4f94aae6eb0cde4532bb"
          }
        },
        "5f00b29edba34a95b296f7d8a64e18df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11ebb8512a3445b289faf693d90be832",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3696345013f04367a38c04f23a5cd7a9"
          }
        },
        "f513dfab11b04d92b7e772b68afa28dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_86caeaa8088b452b8bdf8ddc33d48457",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.83M/4.83M [00:00&lt;00:00, 25.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eeecc3964fef4d6baced68377f0e173e"
          }
        },
        "cb96c91476c843848f4fe29561abf0e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c211cbbacf4e4f94aae6eb0cde4532bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11ebb8512a3445b289faf693d90be832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3696345013f04367a38c04f23a5cd7a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86caeaa8088b452b8bdf8ddc33d48457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eeecc3964fef4d6baced68377f0e173e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "899a2758232d4155b4f51b8aee5ea5d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_062ea540cbb84d838561f4857560b4b0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_201c886ce0bc437fa694709b51e59a98",
              "IPY_MODEL_02e7f83d122e4c1886cad0367837b36f",
              "IPY_MODEL_3209c11482be4ca388261806487ffe6a"
            ]
          }
        },
        "062ea540cbb84d838561f4857560b4b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "201c886ce0bc437fa694709b51e59a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c572ebbe55bc40b9a26469304703607d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e5e87627726405981022105722dd7f5"
          }
        },
        "02e7f83d122e4c1886cad0367837b36f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_70e364b1cb7a4d69b48aaae46270659c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9096718,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9096718,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d16bf0eeadd44d989aca7c0b2390f452"
          }
        },
        "3209c11482be4ca388261806487ffe6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2ed8fbf4e6943699e0a10cda55b3511",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8.68M/8.68M [00:00&lt;00:00, 27.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4deb086037404f51a8c0c9a54b80e50e"
          }
        },
        "c572ebbe55bc40b9a26469304703607d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e5e87627726405981022105722dd7f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70e364b1cb7a4d69b48aaae46270659c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d16bf0eeadd44d989aca7c0b2390f452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2ed8fbf4e6943699e0a10cda55b3511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4deb086037404f51a8c0c9a54b80e50e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "122040e698984dc8972a9089b5a0831c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_74e917ab83c34bb6b7ff416063539d75",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f5539e4cc0c48b4b89e433fc7113592",
              "IPY_MODEL_94626748cc2c4664a1f0524d5723b53b",
              "IPY_MODEL_cc75e365031a4f808c76ec6681a72767"
            ]
          }
        },
        "74e917ab83c34bb6b7ff416063539d75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f5539e4cc0c48b4b89e433fc7113592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_03ea67b9a3a84e3d8726c1807efd1f48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3cfa31612ee048a08ee8495304584100"
          }
        },
        "94626748cc2c4664a1f0524d5723b53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9019c37dabe34d17b65d8f85a583be6e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2244861551,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2244861551,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2df54b1b4b224abfa3416f448469e3f0"
          }
        },
        "cc75e365031a4f808c76ec6681a72767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cbc09dd2171a405599680e65137ab32f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.09G/2.09G [01:23&lt;00:00, 13.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b93fcb9c2cd4359ab3b90a03cb2a2fb"
          }
        },
        "03ea67b9a3a84e3d8726c1807efd1f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3cfa31612ee048a08ee8495304584100": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9019c37dabe34d17b65d8f85a583be6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2df54b1b4b224abfa3416f448469e3f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbc09dd2171a405599680e65137ab32f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b93fcb9c2cd4359ab3b90a03cb2a2fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GGoYoungHee/Dacon_koreanNLP/blob/main/koBERT_lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXsLeV9wIoD7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH =  '/content/drive/MyDrive/Dacon_KoreanNLP'\n",
        "\n",
        "train = pd.read_csv(os.path.join(PATH, 'open/train_data.csv'), encoding='utf-8')\n",
        "test = pd.read_csv(os.path.join(PATH, 'open/test_data.csv'), encoding='utf-8')\n",
        "\n",
        "train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "aMjG1U4yIrsR",
        "outputId": "1592c96e-fe19-4878-db4c-d7c5f156231f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-df54897f-42b6-4702-bf4e-e1cd4d5bbba7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...</td>\n",
              "      <td>씨름의 여자들의 놀이이다.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...</td>\n",
              "      <td>자작극을 벌인 이는 3명이다.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.</td>\n",
              "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
              "      <td>원주민들은 종합대책에 만족했다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...</td>\n",
              "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df54897f-42b6-4702-bf4e-e1cd4d5bbba7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df54897f-42b6-4702-bf4e-e1cd4d5bbba7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df54897f-42b6-4702-bf4e-e1cd4d5bbba7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   index  ...          label\n",
              "0      0  ...  contradiction\n",
              "1      1  ...  contradiction\n",
              "2      2  ...     entailment\n",
              "3      3  ...        neutral\n",
              "4      4  ...        neutral\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.info(), end='\\n\\n')\n",
        "print(test.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s4-HenWI2oW",
        "outputId": "5cc2956b-3697-4e80-a29d-e425ae62fe45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 24998 entries, 0 to 24997\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   index       24998 non-null  int64 \n",
            " 1   premise     24998 non-null  object\n",
            " 2   hypothesis  24998 non-null  object\n",
            " 3   label       24998 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 781.3+ KB\n",
            "None\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1666 entries, 0 to 1665\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   index       1666 non-null   int64 \n",
            " 1   premise     1666 non-null   object\n",
            " 2   hypothesis  1666 non-null   object\n",
            " 3   label       1666 non-null   object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 52.2+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train Columns: ', train.columns)\n",
        "print('Test Columns: ', test.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdOYdcbzI5lC",
        "outputId": "e125473d-2375-47f3-c16e-4c5d85cfe3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Columns:  Index(['index', 'premise', 'hypothesis', 'label'], dtype='object')\n",
            "Test Columns:  Index(['index', 'premise', 'hypothesis', 'label'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train Label: ', train['label'].value_counts(), sep='\\n', end='\\n\\n')\n",
        "print('Test Label: ', test['label'].value_counts(), sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmgRYCwWI67X",
        "outputId": "92824206-2961-4b3e-8786-31439ab0ae28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Label: \n",
            "entailment       8561\n",
            "contradiction    8489\n",
            "neutral          7948\n",
            "Name: label, dtype: int64\n",
            "\n",
            "Test Label: \n",
            "answer    1666\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train Null: ', train.isnull().sum(), sep='\\n', end='\\n\\n')\n",
        "print('Test Null: ', test.isnull().sum(), sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhBfKphKI7_Q",
        "outputId": "b1a0d9b8-322b-4a98-bec0-7819ab7c513d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Null: \n",
            "index         0\n",
            "premise       0\n",
            "hypothesis    0\n",
            "label         0\n",
            "dtype: int64\n",
            "\n",
            "Test Null: \n",
            "index         0\n",
            "premise       0\n",
            "hypothesis    0\n",
            "label         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature = train['label']\n",
        "\n",
        "plt.figure(figsize=(10,7.5))\n",
        "plt.title('Label Count', fontsize=20)\n",
        "\n",
        "temp = feature.value_counts()\n",
        "plt.bar(temp.keys(), temp.values, width=0.5, color='b', alpha=0.5)\n",
        "plt.text(-0.05, temp.values[0]+20, s=temp.values[0])\n",
        "plt.text(0.95, temp.values[1]+20, s=temp.values[1])\n",
        "plt.text(1.95, temp.values[2]+20, s=temp.values[2])\n",
        "\n",
        "plt.xticks(temp.keys(), fontsize=12) # x축 값, 폰트 크기 설정\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # 레이아웃 설정\n",
        "plt.show() # 그래프 나타내기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "hfS-qjxBI9Ri",
        "outputId": "31c2e91c-16b3-4774-b319-ecaeb15bbc27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x540 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = np.max(train['premise'].str.len())\n",
        "min_len = np.min(train['premise'].str.len())\n",
        "mean_len = np.mean(train['premise'].str.len())\n",
        "\n",
        "print('Max Premise Length: ', max_len)\n",
        "print('Min Premise Length: ', min_len)\n",
        "print('Mean Premise Lenght: ', mean_len, '\\n')\n",
        "\n",
        "max_len = np.max(train['hypothesis'].str.len())\n",
        "min_len = np.min(train['hypothesis'].str.len())\n",
        "mean_len = np.mean(train['hypothesis'].str.len())\n",
        "\n",
        "print('Max Hypothesis Length: ', max_len)\n",
        "print('Min Hypothesis Length: ', min_len)\n",
        "print('Mean Hypothesis Lenght: ', mean_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id064RCuI_qw",
        "outputId": "496f2dd0-140b-4f6c-95c8-91098ad9f4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Premise Length:  90\n",
            "Min Premise Length:  19\n",
            "Mean Premise Lenght:  45.406552524201935 \n",
            "\n",
            "Max Hypothesis Length:  103\n",
            "Min Hypothesis Length:  5\n",
            "Mean Hypothesis Lenght:  24.924433954716378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "plt.figure(figsize=(10,7.5))\n",
        "plt.title('Premise Length', fontsize=20)\n",
        "\n",
        "plt.hist(train['premise'].str.len(), alpha=0.5, color='orange')\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # 레이아웃 설정\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "t6DTxFfwJBU-",
        "outputId": "8a1751b1-7e7c-49fb-bac8-f14214267b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x540 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test Preprocessing"
      ],
      "metadata": {
        "id": "VBKareb-JD7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['premise'] = train['premise'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')\n",
        "test['premise'] = test['premise'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]\", \"\")\n",
        "train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "-5hUCNkpJClf",
        "outputId": "9dcab0e2-6fc2-4a1b-ced4-3564f5783dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e98c2137-0e68-4bbe-adc7-7b2cfa76bae2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...</td>\n",
              "      <td>씨름의 여자들의 놀이이다.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...</td>\n",
              "      <td>자작극을 벌인 이는 3명이다.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다</td>\n",
              "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
              "      <td>원주민들은 종합대책에 만족했다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...</td>\n",
              "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e98c2137-0e68-4bbe-adc7-7b2cfa76bae2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e98c2137-0e68-4bbe-adc7-7b2cfa76bae2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e98c2137-0e68-4bbe-adc7-7b2cfa76bae2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   index  ...          label\n",
              "0      0  ...  contradiction\n",
              "1      1  ...  contradiction\n",
              "2      2  ...     entailment\n",
              "3      3  ...        neutral\n",
              "4      4  ...        neutral\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['hypothesis'] = train['hypothesis'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')\n",
        "test['hypothesis'] = test['hypothesis'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]\", \"\")\n",
        "train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "MwgFgoqaJFp2",
        "outputId": "c9e80baa-4585-4af3-b960-f22f2573c4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a0d5771d-1bad-4755-977b-1c6b80411ee5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...</td>\n",
              "      <td>씨름의 여자들의 놀이이다</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...</td>\n",
              "      <td>자작극을 벌인 이는 3명이다</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다</td>\n",
              "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
              "      <td>원주민들은 종합대책에 만족했다</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...</td>\n",
              "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0d5771d-1bad-4755-977b-1c6b80411ee5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0d5771d-1bad-4755-977b-1c6b80411ee5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0d5771d-1bad-4755-977b-1c6b80411ee5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   index  ...          label\n",
              "0      0  ...  contradiction\n",
              "1      1  ...  contradiction\n",
              "2      2  ...     entailment\n",
              "3      3  ...        neutral\n",
              "4      4  ...        neutral\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# modeling"
      ],
      "metadata": {
        "id": "Nd9Ehb1pJHvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt5Dgq1iJGyz",
        "outputId": "e2d10de0-1547-40bb-a842-1d4a321b473d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer\n",
        "from transformers import EarlyStoppingCallback"
      ],
      "metadata": {
        "id": "lcAFAxWcJJRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed 고정, GPU 설정\n",
        "def seed_everything(seed:int = 1004):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmMOiThQJNGP",
        "outputId": "94f0bc18-74bc-4e88-fdf5-cc4981b3ed1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Tokenizer, Model"
      ],
      "metadata": {
        "id": "hdeSokgHJQC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'xlm-roberta-large'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "tIqJMt8jJNFC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "646399107d1a430a801ae417fb1e2bfb",
            "eb4cf5a6ec98416a960e16b425fbbf75",
            "458160224e2d4d148a2c6392551dac44",
            "2243391d21c14eb995d6328c0d6f2c17",
            "5f8d2ace9853473dbf79b69f9b183740",
            "98b2bea8376a4747ad5777e47823aa55",
            "368100c081d24b04b7d050e414b26bb6",
            "966c67dba33743ceb608611d17ff7128",
            "cad9b92241c4477e87d822dd392c1604",
            "ad1ff2b3f96346749a652689842822be",
            "a3c9159ccd6a4b2a8d170d6f01b9b4d8",
            "fcde5e04cc34425faa75df386c848140",
            "2f9ecde7dee34a68b6bbfff095ffb8a7",
            "5221ea0d43004660a12a18b463b8f078",
            "5f00b29edba34a95b296f7d8a64e18df",
            "f513dfab11b04d92b7e772b68afa28dc",
            "cb96c91476c843848f4fe29561abf0e4",
            "c211cbbacf4e4f94aae6eb0cde4532bb",
            "11ebb8512a3445b289faf693d90be832",
            "3696345013f04367a38c04f23a5cd7a9",
            "86caeaa8088b452b8bdf8ddc33d48457",
            "eeecc3964fef4d6baced68377f0e173e",
            "899a2758232d4155b4f51b8aee5ea5d1",
            "062ea540cbb84d838561f4857560b4b0",
            "201c886ce0bc437fa694709b51e59a98",
            "02e7f83d122e4c1886cad0367837b36f",
            "3209c11482be4ca388261806487ffe6a",
            "c572ebbe55bc40b9a26469304703607d",
            "3e5e87627726405981022105722dd7f5",
            "70e364b1cb7a4d69b48aaae46270659c",
            "d16bf0eeadd44d989aca7c0b2390f452",
            "e2ed8fbf4e6943699e0a10cda55b3511",
            "4deb086037404f51a8c0c9a54b80e50e"
          ]
        },
        "outputId": "8357ef62-2bc3-48ae-fe29-f290544029b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "https://huggingface.co/xlm-roberta-large/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp2og23_2u\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "646399107d1a430a801ae417fb1e2bfb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/513 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/xlm-roberta-large/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/4d7a1550c9ab8701667bc307a1213c040fcc06dc87a5e4994e72aecc0d7e0337.302e267433fe7c84959a639e9c7c555043daa4020c0daf311785b53de7b8685e\n",
            "creating metadata file for /root/.cache/huggingface/transformers/4d7a1550c9ab8701667bc307a1213c040fcc06dc87a5e4994e72aecc0d7e0337.302e267433fe7c84959a639e9c7c555043daa4020c0daf311785b53de7b8685e\n",
            "loading configuration file https://huggingface.co/xlm-roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/4d7a1550c9ab8701667bc307a1213c040fcc06dc87a5e4994e72aecc0d7e0337.302e267433fe7c84959a639e9c7c555043daa4020c0daf311785b53de7b8685e\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "https://huggingface.co/xlm-roberta-large/resolve/main/sentencepiece.bpe.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpp91cghbw\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcde5e04cc34425faa75df386c848140",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/xlm-roberta-large/resolve/main/sentencepiece.bpe.model in cache at /root/.cache/huggingface/transformers/dc0198bb42e28700de2a550508894cf6c5202c38c7aff44b71a055950dfc2f99.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\n",
            "creating metadata file for /root/.cache/huggingface/transformers/dc0198bb42e28700de2a550508894cf6c5202c38c7aff44b71a055950dfc2f99.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\n",
            "https://huggingface.co/xlm-roberta-large/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpvpua8dr5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "899a2758232d4155b4f51b8aee5ea5d1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/xlm-roberta-large/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/7766c86e10505ed9b39af34e456480399bf06e35b36b8f2b917460a2dbe94e59.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\n",
            "creating metadata file for /root/.cache/huggingface/transformers/7766c86e10505ed9b39af34e456480399bf06e35b36b8f2b917460a2dbe94e59.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\n",
            "loading file https://huggingface.co/xlm-roberta-large/resolve/main/sentencepiece.bpe.model from cache at /root/.cache/huggingface/transformers/dc0198bb42e28700de2a550508894cf6c5202c38c7aff44b71a055950dfc2f99.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\n",
            "loading file https://huggingface.co/xlm-roberta-large/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/7766c86e10505ed9b39af34e456480399bf06e35b36b8f2b917460a2dbe94e59.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\n",
            "loading file https://huggingface.co/xlm-roberta-large/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/xlm-roberta-large/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/xlm-roberta-large/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/xlm-roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/4d7a1550c9ab8701667bc307a1213c040fcc06dc87a5e4994e72aecc0d7e0337.302e267433fe7c84959a639e9c7c555043daa4020c0daf311785b53de7b8685e\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
        "config.num_labels = 3\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n",
        "\n",
        "print(model)\n",
        "print(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "122040e698984dc8972a9089b5a0831c",
            "74e917ab83c34bb6b7ff416063539d75",
            "4f5539e4cc0c48b4b89e433fc7113592",
            "94626748cc2c4664a1f0524d5723b53b",
            "cc75e365031a4f808c76ec6681a72767",
            "03ea67b9a3a84e3d8726c1807efd1f48",
            "3cfa31612ee048a08ee8495304584100",
            "9019c37dabe34d17b65d8f85a583be6e",
            "2df54b1b4b224abfa3416f448469e3f0",
            "cbc09dd2171a405599680e65137ab32f",
            "1b93fcb9c2cd4359ab3b90a03cb2a2fb"
          ]
        },
        "id": "ypTv8pKuJNDf",
        "outputId": "621420a4-dfce-4198-9a43-067e9c78edfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/xlm-roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/4d7a1550c9ab8701667bc307a1213c040fcc06dc87a5e4994e72aecc0d7e0337.302e267433fe7c84959a639e9c7c555043daa4020c0daf311785b53de7b8685e\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "https://huggingface.co/xlm-roberta-large/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpwznhv12t\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "122040e698984dc8972a9089b5a0831c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.09G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/xlm-roberta-large/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/4b3ca85a63804fb7cd317765d9de19ce6208ee0fc9691b209384ee7cfd9cb3b9.64b4693d874c772310b8acda9a1193cfade77d56795a9b488e612f198b68f6f7\n",
            "creating metadata file for /root/.cache/huggingface/transformers/4b3ca85a63804fb7cd317765d9de19ce6208ee0fc9691b209384ee7cfd9cb3b9.64b4693d874c772310b8acda9a1193cfade77d56795a9b488e612f198b68f6f7\n",
            "loading weights file https://huggingface.co/xlm-roberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4b3ca85a63804fb7cd317765d9de19ce6208ee0fc9691b209384ee7cfd9cb3b9.64b4693d874c772310b8acda9a1193cfade77d56795a9b488e612f198b68f6f7\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XLMRobertaForSequenceClassification(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 1024)\n",
            "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (12): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (13): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (14): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (15): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (16): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (17): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (18): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (19): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (20): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (21): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (22): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (23): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (classifier): RobertaClassificationHead(\n",
            "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
            "  )\n",
            ")\n",
            "XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing"
      ],
      "metadata": {
        "id": "tGSiAlpzJYLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, eval_dataset = train_test_split(train, test_size=0.2, shuffle=True, stratify=train['label'])\n",
        "\n",
        "tokenized_train = tokenizer(\n",
        "    list(train_dataset['premise']),\n",
        "    list(train_dataset['hypothesis']),\n",
        "    return_tensors=\"pt\",\n",
        "    max_length=256, # Max_Length = 190\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True\n",
        ")\n",
        "\n",
        "tokenized_eval = tokenizer(\n",
        "    list(eval_dataset['premise']),\n",
        "    list(eval_dataset['hypothesis']),\n",
        "    return_tensors=\"pt\",\n",
        "    max_length=256,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True\n",
        ")\n",
        "\n",
        "print(tokenized_train['input_ids'][0])\n",
        "print(tokenizer.decode(tokenized_train['input_ids'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjiZOoihJM96",
        "outputId": "33515259-65b6-40bc-d756-e1e88c113c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([     0,   1504,   2905,   7046,    713,  93278, 121980,   7342, 120350,\n",
            "          1504,   7046,   5358,    367,   3626,  24247,   1571,  68191, 121980,\n",
            "         20945,   5770,  25547,  11031,   7286,   2020,  16661,  24386,   7094,\n",
            "         21806,  17937,      2,      2,   1504,   7046,   5358,   1291,  20945,\n",
            "          5770,  25547,    697,  90036,    993,      6,  61971,  31864,      2,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1])\n",
            "<s> 이정재가 삼성그룹 부회장 이재용의 전처인 대상그룹 임세령 상무와 열애중이라고 합니다</s></s> 이재용과 임세령은 결혼한 적이 없다</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, pair_dataset, label):\n",
        "        self.pair_dataset = pair_dataset\n",
        "        self.label = label\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n",
        "        item['label'] = torch.tensor(self.label[idx])\n",
        "        \n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)"
      ],
      "metadata": {
        "id": "CZHhkJeLJM75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_to_num(label):\n",
        "    label_dict = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2, \"answer\": 3}\n",
        "    num_label = []\n",
        "\n",
        "    for v in label:\n",
        "        num_label.append(label_dict[v])\n",
        "    \n",
        "    return num_label\n"
      ],
      "metadata": {
        "id": "TRA54MeXJM6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_label = label_to_num(train_dataset['label'].values)\n",
        "eval_label = label_to_num(eval_dataset['label'].values)\n"
      ],
      "metadata": {
        "id": "RSMoAjxAJrYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = BERTDataset(tokenized_train, train_label)\n",
        "eval_dataset = BERTDataset(tokenized_eval, eval_label)\n",
        "\n",
        "print(train_dataset.__len__())\n",
        "print(train_dataset.__getitem__(19997))\n",
        "print(tokenizer.decode(train_dataset.__getitem__(19997)['input_ids']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzZ_BWBXJM4U",
        "outputId": "80c72524-0255-484c-c212-1c197692f608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19998\n",
            "{'input_ids': tensor([     0,   6888,   4087, 120753,      6, 163826,    480,  45585,    367,\n",
            "             6,  54272,  17407,   2171,  40349, 224897,  49496,   8925,    480,\n",
            "         23071, 129459, 167044,   7593,  18971,  38647,   5476,      2,      2,\n",
            "          6888,   4087, 120753,      6, 163826,    480,  45585,    769,      6,\n",
            "         54272,  17407, 144122,   3156,  49496,   8925,   5476,      2,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
            "             1,      1,      1,      1,      1,      1,      1,      1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0]), 'label': tensor(0)}\n",
            "<s> 안드레스 이니에스타의 갑작스런 스페인 귀국에 일본 축구팬들이 당황했다</s></s> 안드레스 이니에스타는 갑작스럽게 귀국했다</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "  \"\"\" validation을 위한 metrics function \"\"\"\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  probs = pred.predictions\n",
        "\n",
        "  # calculate accuracy using sklearn's function\n",
        "  acc = accuracy_score(labels, preds) # 리더보드 평가에는 포함되지 않습니다.\n",
        "\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "  }"
      ],
      "metadata": {
        "id": "WS2GBlqFJM14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_ars = TrainingArguments(\n",
        "    output_dir='./result',\n",
        "    num_train_epochs=7,\n",
        "    per_device_train_batch_size=32,\n",
        "    save_total_limit=5,\n",
        "    save_steps=500,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps = 500,\n",
        "    load_best_model_at_end = True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_ars,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")"
      ],
      "metadata": {
        "id": "nMx7N0nmJM0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0962bb5-c33c-4a66-dffa-dd031506759c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, gc\n",
        "\n",
        "gc.collect()\n",
        "#torch.cuda.empty_cache()\n",
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Jp2NGRtvGIE5",
        "outputId": "1978fae3-f687-4f89-dc63-88c61846ca0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 2            |        cudaMalloc retries: 3         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   14487 MB |   14632 MB |   52254 GB |   52239 GB |\\n|       from large pool |   14481 MB |   14626 MB |   51718 GB |   51704 GB |\\n|       from small pool |       6 MB |      20 MB |     535 GB |     535 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   14487 MB |   14632 MB |   52254 GB |   52239 GB |\\n|       from large pool |   14481 MB |   14626 MB |   51718 GB |   51704 GB |\\n|       from small pool |       6 MB |      20 MB |     535 GB |     535 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   15108 MB |   15108 MB |   21128 MB |    6020 MB |\\n|       from large pool |   15100 MB |   15100 MB |   21106 MB |    6006 MB |\\n|       from small pool |       8 MB |      22 MB |      22 MB |      14 MB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  606262 KB |    1495 MB |   45708 GB |   45708 GB |\\n|       from large pool |  604398 KB |    1493 MB |   45164 GB |   45163 GB |\\n|       from small pool |    1864 KB |      11 MB |     544 GB |     544 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    2029    |    2041    |   20511 K  |   20509 K  |\\n|       from large pool |     946    |     955    |   10554 K  |   10553 K  |\\n|       from small pool |    1083    |    1224    |    9957 K  |    9955 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    2029    |    2041    |   20511 K  |   20509 K  |\\n|       from large pool |     946    |     955    |   10554 K  |   10553 K  |\\n|       from small pool |    1083    |    1224    |    9957 K  |    9955 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     538    |     538    |     756    |     218    |\\n|       from large pool |     534    |     534    |     745    |     211    |\\n|       from small pool |       4    |      11    |      11    |       7    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |     389    |     391    |   10323 K  |   10323 K  |\\n|       from large pool |     329    |     334    |    7100 K  |    7100 K  |\\n|       from small pool |      60    |      63    |    3223 K  |    3223 K  |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "model.save_pretrained('./result/best_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "fyonzgpGJMxe",
        "outputId": "a47aa6a3-e5a9-4111-beca-5f27364ac574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 19998\n",
            "  Num Epochs = 7\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4375\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-1fea62ac79fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./result/best_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1972\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m         )\n\u001b[1;32m   1215\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m         )\n\u001b[1;32m    850\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 15.90 GiB total capacity; 14.17 GiB already allocated; 33.75 MiB free; 14.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "Tokenizer_NAME = \"monologg/distilkobert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(Tokenizer_NAME)\n",
        "#KoBertTokenizer.from_pretrained('monologg/kobert')\n",
        "\n",
        "MODEL_NAME = './result/checkpoint-4000'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.resize_token_embeddings(tokenizer.vocab_size)\n",
        "model.to(device)\n",
        "\n",
        "print(tokenizer)"
      ],
      "metadata": {
        "id": "kOLw1b6CJMsL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8704b4e4-44e4-4598-95c1-223e6d7e1c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/monologg/distilkobert/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/4d5d25a119f63fb5526032bb7cdaf522e10cccab75fe0a539eca437722feca3d.0638161d3d5ebe20c18198663a075aca59b59977a233e0ca4b40737067ea8894\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"monologg/distilkobert\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 3,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"vocab_size\": 8002\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/monologg/distilkobert/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/24ee7d225505ad63bb2e648d8780b76bfbc433a1848223ddadaa89dcd0d9f094.719459e20bc981bc2093e859b02c3a3e51bab724d6b58927b23b512a3981229f\n",
            "loading file https://huggingface.co/monologg/distilkobert/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/monologg/distilkobert/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/monologg/distilkobert/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/monologg/distilkobert/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/bfa179e013deeba2d38650758928909fd8c267d6df8ace54588d1e1cb087f0d2.767d1b760a83978bae6c324157fad57ee513af333a7cea6986e852579f6f0dd1\n",
            "loading configuration file https://huggingface.co/monologg/distilkobert/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/4d5d25a119f63fb5526032bb7cdaf522e10cccab75fe0a539eca437722feca3d.0638161d3d5ebe20c18198663a075aca59b59977a233e0ca4b40737067ea8894\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"monologg/distilkobert\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 3,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"vocab_size\": 8002\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/monologg/distilkobert/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/4d5d25a119f63fb5526032bb7cdaf522e10cccab75fe0a539eca437722feca3d.0638161d3d5ebe20c18198663a075aca59b59977a233e0ca4b40737067ea8894\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"monologg/distilkobert\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 3,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"vocab_size\": 8002\n",
            "}\n",
            "\n",
            "404 Client Error: Not Found for url: https://huggingface.co/./result/checkpoint-4000/resolve/main/config.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1854\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1855\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   2049\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2050\u001b[0;31m             \u001b[0m_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2051\u001b[0m             \u001b[0metag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X-Linked-Etag\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ETag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m_raise_for_status\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   1976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1977\u001b[0;31m     \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/./result/checkpoint-4000/resolve/main/config.json",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-fa55ec4d54b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mMODEL_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./result/checkpoint-4000'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_token_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             config, kwargs = AutoConfig.from_pretrained(\n\u001b[0;32m--> 425\u001b[0;31m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m             )\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;31m# That config file may point us toward another config file to use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             raise EnvironmentError(\n\u001b[0;32m--> 619\u001b[0;31m                 \u001b[0;34m\"We couldn't connect to 'https://huggingface.co/' to load this model and it looks like \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m                 \u001b[0;34mf\"{pretrained_model_name_or_path} is not the path to a directory conaining a {configuration_file} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                 \u001b[0;34m\"file.\\nCheckout your internet connection or see how to run the library in offline mode at \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co/' to load this model and it looks like ./result/checkpoint-4000 is not the path to a directory conaining a config.json file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eTDJnZ7IKhDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_label = label_to_num(test['label'].values)\n",
        "\n",
        "tokenized_test = tokenizer(\n",
        "    list(test['premise']),\n",
        "    list(test['hypothesis']),\n",
        "    return_tensors=\"pt\",\n",
        "    max_length=128,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True\n",
        ")\n",
        "\n",
        "test_dataset = BERTDataset(tokenized_test, test_label)\n",
        "\n",
        "print(test_dataset.__len__())\n",
        "print(test_dataset.__getitem__(1665))\n",
        "print(tokenizer.decode(test_dataset.__getitem__(6)['input_ids']))"
      ],
      "metadata": {
        "id": "W1U5EiHsJMqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c75d7b-9e9e-43a5-b08b-f7180ed75572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1666\n",
            "{'input_ids': tensor([   2, 5663,    0,    0, 5585,    0, 6224,    0,    3, 5663,    0,    0,\n",
            "           0,    0,    0,    3,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(3)}\n",
            "[CLS] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [SEP] [UNK] [UNK] [UNK] [UNK] [UNK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "output_pred = []\n",
        "output_prob = []\n",
        "\n",
        "for i, data in enumerate(tqdm(dataloader)):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=data['input_ids'].to(device),\n",
        "            attention_mask=data['attention_mask'].to(device),\n",
        "            token_type_ids=data['token_type_ids'].to(device)\n",
        "        )\n",
        "    logits = outputs[0]\n",
        "    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    result = np.argmax(logits, axis=-1)\n",
        "\n",
        "    output_pred.append(result)\n",
        "    output_prob.append(prob)\n",
        "  \n",
        "pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
        "print(pred_answer)"
      ],
      "metadata": {
        "id": "OduIxBieJMoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d06c3797-7931-43f7-fc00-7d4ffc8f580c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 105/105 [00:02<00:00, 36.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def num_to_label(label):\n",
        "    label_dict = {0: \"entailment\", 1: \"contradiction\", 2: \"neutral\"}\n",
        "    str_label = []\n",
        "\n",
        "    for i, v in enumerate(label):\n",
        "        str_label.append([i,label_dict[v]])\n",
        "    \n",
        "    return str_label\n",
        "\n",
        "answer = num_to_label(pred_answer)"
      ],
      "metadata": {
        "id": "bWiaO5OlJMmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b509c43-439f-4d21-b31c-96964c845c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 'entailment'], [1, 'entailment'], [2, 'entailment'], [3, 'entailment'], [4, 'entailment'], [5, 'entailment'], [6, 'entailment'], [7, 'entailment'], [8, 'entailment'], [9, 'entailment'], [10, 'entailment'], [11, 'entailment'], [12, 'entailment'], [13, 'entailment'], [14, 'entailment'], [15, 'entailment'], [16, 'entailment'], [17, 'entailment'], [18, 'entailment'], [19, 'entailment'], [20, 'entailment'], [21, 'entailment'], [22, 'entailment'], [23, 'entailment'], [24, 'entailment'], [25, 'entailment'], [26, 'entailment'], [27, 'entailment'], [28, 'entailment'], [29, 'entailment'], [30, 'entailment'], [31, 'entailment'], [32, 'entailment'], [33, 'entailment'], [34, 'entailment'], [35, 'entailment'], [36, 'entailment'], [37, 'entailment'], [38, 'entailment'], [39, 'entailment'], [40, 'entailment'], [41, 'entailment'], [42, 'entailment'], [43, 'entailment'], [44, 'entailment'], [45, 'entailment'], [46, 'entailment'], [47, 'entailment'], [48, 'entailment'], [49, 'entailment'], [50, 'entailment'], [51, 'entailment'], [52, 'entailment'], [53, 'entailment'], [54, 'entailment'], [55, 'entailment'], [56, 'entailment'], [57, 'entailment'], [58, 'entailment'], [59, 'entailment'], [60, 'entailment'], [61, 'entailment'], [62, 'entailment'], [63, 'entailment'], [64, 'entailment'], [65, 'entailment'], [66, 'entailment'], [67, 'entailment'], [68, 'entailment'], [69, 'entailment'], [70, 'entailment'], [71, 'entailment'], [72, 'entailment'], [73, 'entailment'], [74, 'entailment'], [75, 'entailment'], [76, 'entailment'], [77, 'entailment'], [78, 'entailment'], [79, 'entailment'], [80, 'entailment'], [81, 'entailment'], [82, 'entailment'], [83, 'entailment'], [84, 'entailment'], [85, 'entailment'], [86, 'entailment'], [87, 'entailment'], [88, 'entailment'], [89, 'entailment'], [90, 'entailment'], [91, 'entailment'], [92, 'entailment'], [93, 'entailment'], [94, 'entailment'], [95, 'entailment'], [96, 'entailment'], [97, 'entailment'], [98, 'entailment'], [99, 'entailment'], [100, 'entailment'], [101, 'entailment'], [102, 'entailment'], [103, 'entailment'], [104, 'entailment'], [105, 'entailment'], [106, 'entailment'], [107, 'entailment'], [108, 'entailment'], [109, 'entailment'], [110, 'entailment'], [111, 'entailment'], [112, 'entailment'], [113, 'entailment'], [114, 'entailment'], [115, 'entailment'], [116, 'entailment'], [117, 'entailment'], [118, 'entailment'], [119, 'entailment'], [120, 'entailment'], [121, 'entailment'], [122, 'entailment'], [123, 'entailment'], [124, 'entailment'], [125, 'entailment'], [126, 'entailment'], [127, 'entailment'], [128, 'entailment'], [129, 'entailment'], [130, 'entailment'], [131, 'entailment'], [132, 'entailment'], [133, 'entailment'], [134, 'entailment'], [135, 'entailment'], [136, 'entailment'], [137, 'entailment'], [138, 'entailment'], [139, 'entailment'], [140, 'entailment'], [141, 'entailment'], [142, 'entailment'], [143, 'entailment'], [144, 'entailment'], [145, 'entailment'], [146, 'entailment'], [147, 'entailment'], [148, 'entailment'], [149, 'entailment'], [150, 'entailment'], [151, 'entailment'], [152, 'entailment'], [153, 'entailment'], [154, 'entailment'], [155, 'entailment'], [156, 'entailment'], [157, 'entailment'], [158, 'entailment'], [159, 'entailment'], [160, 'entailment'], [161, 'entailment'], [162, 'entailment'], [163, 'entailment'], [164, 'entailment'], [165, 'entailment'], [166, 'entailment'], [167, 'entailment'], [168, 'entailment'], [169, 'entailment'], [170, 'entailment'], [171, 'entailment'], [172, 'entailment'], [173, 'entailment'], [174, 'entailment'], [175, 'entailment'], [176, 'entailment'], [177, 'entailment'], [178, 'entailment'], [179, 'entailment'], [180, 'entailment'], [181, 'entailment'], [182, 'entailment'], [183, 'entailment'], [184, 'entailment'], [185, 'entailment'], [186, 'entailment'], [187, 'entailment'], [188, 'entailment'], [189, 'entailment'], [190, 'entailment'], [191, 'entailment'], [192, 'entailment'], [193, 'entailment'], [194, 'entailment'], [195, 'entailment'], [196, 'entailment'], [197, 'entailment'], [198, 'entailment'], [199, 'entailment'], [200, 'entailment'], [201, 'entailment'], [202, 'entailment'], [203, 'entailment'], [204, 'entailment'], [205, 'entailment'], [206, 'entailment'], [207, 'entailment'], [208, 'entailment'], [209, 'entailment'], [210, 'entailment'], [211, 'entailment'], [212, 'entailment'], [213, 'entailment'], [214, 'entailment'], [215, 'entailment'], [216, 'entailment'], [217, 'entailment'], [218, 'entailment'], [219, 'entailment'], [220, 'entailment'], [221, 'entailment'], [222, 'entailment'], [223, 'entailment'], [224, 'entailment'], [225, 'entailment'], [226, 'entailment'], [227, 'entailment'], [228, 'entailment'], [229, 'entailment'], [230, 'entailment'], [231, 'entailment'], [232, 'entailment'], [233, 'entailment'], [234, 'entailment'], [235, 'entailment'], [236, 'entailment'], [237, 'entailment'], [238, 'entailment'], [239, 'entailment'], [240, 'entailment'], [241, 'entailment'], [242, 'entailment'], [243, 'entailment'], [244, 'entailment'], [245, 'entailment'], [246, 'entailment'], [247, 'entailment'], [248, 'entailment'], [249, 'entailment'], [250, 'entailment'], [251, 'entailment'], [252, 'entailment'], [253, 'entailment'], [254, 'entailment'], [255, 'entailment'], [256, 'entailment'], [257, 'entailment'], [258, 'entailment'], [259, 'entailment'], [260, 'entailment'], [261, 'entailment'], [262, 'entailment'], [263, 'entailment'], [264, 'entailment'], [265, 'entailment'], [266, 'entailment'], [267, 'entailment'], [268, 'entailment'], [269, 'entailment'], [270, 'entailment'], [271, 'entailment'], [272, 'entailment'], [273, 'entailment'], [274, 'entailment'], [275, 'entailment'], [276, 'entailment'], [277, 'entailment'], [278, 'entailment'], [279, 'entailment'], [280, 'entailment'], [281, 'entailment'], [282, 'entailment'], [283, 'entailment'], [284, 'entailment'], [285, 'entailment'], [286, 'entailment'], [287, 'entailment'], [288, 'entailment'], [289, 'entailment'], [290, 'entailment'], [291, 'entailment'], [292, 'entailment'], [293, 'entailment'], [294, 'entailment'], [295, 'entailment'], [296, 'entailment'], [297, 'entailment'], [298, 'entailment'], [299, 'entailment'], [300, 'entailment'], [301, 'entailment'], [302, 'entailment'], [303, 'entailment'], [304, 'entailment'], [305, 'entailment'], [306, 'entailment'], [307, 'entailment'], [308, 'entailment'], [309, 'entailment'], [310, 'entailment'], [311, 'entailment'], [312, 'entailment'], [313, 'entailment'], [314, 'entailment'], [315, 'entailment'], [316, 'entailment'], [317, 'entailment'], [318, 'entailment'], [319, 'entailment'], [320, 'entailment'], [321, 'entailment'], [322, 'entailment'], [323, 'entailment'], [324, 'entailment'], [325, 'entailment'], [326, 'entailment'], [327, 'entailment'], [328, 'entailment'], [329, 'entailment'], [330, 'entailment'], [331, 'entailment'], [332, 'entailment'], [333, 'entailment'], [334, 'entailment'], [335, 'entailment'], [336, 'entailment'], [337, 'entailment'], [338, 'entailment'], [339, 'entailment'], [340, 'entailment'], [341, 'entailment'], [342, 'entailment'], [343, 'entailment'], [344, 'entailment'], [345, 'entailment'], [346, 'entailment'], [347, 'entailment'], [348, 'entailment'], [349, 'entailment'], [350, 'entailment'], [351, 'entailment'], [352, 'entailment'], [353, 'entailment'], [354, 'entailment'], [355, 'entailment'], [356, 'entailment'], [357, 'entailment'], [358, 'entailment'], [359, 'entailment'], [360, 'entailment'], [361, 'entailment'], [362, 'entailment'], [363, 'entailment'], [364, 'entailment'], [365, 'entailment'], [366, 'entailment'], [367, 'entailment'], [368, 'entailment'], [369, 'entailment'], [370, 'entailment'], [371, 'entailment'], [372, 'entailment'], [373, 'entailment'], [374, 'entailment'], [375, 'entailment'], [376, 'entailment'], [377, 'entailment'], [378, 'entailment'], [379, 'entailment'], [380, 'entailment'], [381, 'entailment'], [382, 'entailment'], [383, 'entailment'], [384, 'entailment'], [385, 'entailment'], [386, 'entailment'], [387, 'entailment'], [388, 'entailment'], [389, 'entailment'], [390, 'entailment'], [391, 'entailment'], [392, 'entailment'], [393, 'entailment'], [394, 'entailment'], [395, 'entailment'], [396, 'entailment'], [397, 'entailment'], [398, 'entailment'], [399, 'entailment'], [400, 'entailment'], [401, 'entailment'], [402, 'entailment'], [403, 'entailment'], [404, 'entailment'], [405, 'entailment'], [406, 'entailment'], [407, 'entailment'], [408, 'entailment'], [409, 'entailment'], [410, 'entailment'], [411, 'entailment'], [412, 'entailment'], [413, 'entailment'], [414, 'entailment'], [415, 'entailment'], [416, 'entailment'], [417, 'entailment'], [418, 'entailment'], [419, 'entailment'], [420, 'entailment'], [421, 'entailment'], [422, 'entailment'], [423, 'entailment'], [424, 'entailment'], [425, 'entailment'], [426, 'entailment'], [427, 'entailment'], [428, 'entailment'], [429, 'entailment'], [430, 'entailment'], [431, 'entailment'], [432, 'entailment'], [433, 'entailment'], [434, 'entailment'], [435, 'entailment'], [436, 'entailment'], [437, 'entailment'], [438, 'entailment'], [439, 'entailment'], [440, 'entailment'], [441, 'entailment'], [442, 'entailment'], [443, 'entailment'], [444, 'entailment'], [445, 'entailment'], [446, 'entailment'], [447, 'entailment'], [448, 'entailment'], [449, 'entailment'], [450, 'entailment'], [451, 'entailment'], [452, 'entailment'], [453, 'entailment'], [454, 'entailment'], [455, 'entailment'], [456, 'entailment'], [457, 'entailment'], [458, 'entailment'], [459, 'entailment'], [460, 'entailment'], [461, 'entailment'], [462, 'entailment'], [463, 'entailment'], [464, 'entailment'], [465, 'entailment'], [466, 'entailment'], [467, 'entailment'], [468, 'entailment'], [469, 'entailment'], [470, 'entailment'], [471, 'entailment'], [472, 'entailment'], [473, 'entailment'], [474, 'entailment'], [475, 'entailment'], [476, 'entailment'], [477, 'entailment'], [478, 'entailment'], [479, 'entailment'], [480, 'entailment'], [481, 'entailment'], [482, 'entailment'], [483, 'entailment'], [484, 'entailment'], [485, 'entailment'], [486, 'entailment'], [487, 'entailment'], [488, 'entailment'], [489, 'entailment'], [490, 'entailment'], [491, 'entailment'], [492, 'entailment'], [493, 'entailment'], [494, 'entailment'], [495, 'entailment'], [496, 'entailment'], [497, 'entailment'], [498, 'entailment'], [499, 'entailment'], [500, 'entailment'], [501, 'entailment'], [502, 'entailment'], [503, 'entailment'], [504, 'entailment'], [505, 'entailment'], [506, 'entailment'], [507, 'entailment'], [508, 'entailment'], [509, 'entailment'], [510, 'entailment'], [511, 'entailment'], [512, 'entailment'], [513, 'entailment'], [514, 'entailment'], [515, 'entailment'], [516, 'entailment'], [517, 'entailment'], [518, 'entailment'], [519, 'entailment'], [520, 'entailment'], [521, 'entailment'], [522, 'entailment'], [523, 'entailment'], [524, 'entailment'], [525, 'entailment'], [526, 'entailment'], [527, 'entailment'], [528, 'entailment'], [529, 'entailment'], [530, 'entailment'], [531, 'entailment'], [532, 'entailment'], [533, 'entailment'], [534, 'entailment'], [535, 'entailment'], [536, 'entailment'], [537, 'entailment'], [538, 'entailment'], [539, 'entailment'], [540, 'entailment'], [541, 'entailment'], [542, 'entailment'], [543, 'entailment'], [544, 'entailment'], [545, 'entailment'], [546, 'entailment'], [547, 'entailment'], [548, 'entailment'], [549, 'entailment'], [550, 'entailment'], [551, 'entailment'], [552, 'entailment'], [553, 'entailment'], [554, 'entailment'], [555, 'entailment'], [556, 'entailment'], [557, 'entailment'], [558, 'entailment'], [559, 'entailment'], [560, 'entailment'], [561, 'entailment'], [562, 'entailment'], [563, 'entailment'], [564, 'entailment'], [565, 'entailment'], [566, 'entailment'], [567, 'entailment'], [568, 'entailment'], [569, 'entailment'], [570, 'entailment'], [571, 'entailment'], [572, 'entailment'], [573, 'entailment'], [574, 'entailment'], [575, 'entailment'], [576, 'entailment'], [577, 'entailment'], [578, 'entailment'], [579, 'entailment'], [580, 'entailment'], [581, 'entailment'], [582, 'entailment'], [583, 'entailment'], [584, 'entailment'], [585, 'entailment'], [586, 'entailment'], [587, 'entailment'], [588, 'entailment'], [589, 'entailment'], [590, 'entailment'], [591, 'entailment'], [592, 'entailment'], [593, 'entailment'], [594, 'entailment'], [595, 'entailment'], [596, 'entailment'], [597, 'entailment'], [598, 'entailment'], [599, 'entailment'], [600, 'entailment'], [601, 'entailment'], [602, 'entailment'], [603, 'entailment'], [604, 'entailment'], [605, 'entailment'], [606, 'entailment'], [607, 'entailment'], [608, 'entailment'], [609, 'entailment'], [610, 'entailment'], [611, 'entailment'], [612, 'entailment'], [613, 'entailment'], [614, 'entailment'], [615, 'entailment'], [616, 'entailment'], [617, 'entailment'], [618, 'entailment'], [619, 'entailment'], [620, 'entailment'], [621, 'entailment'], [622, 'entailment'], [623, 'entailment'], [624, 'entailment'], [625, 'entailment'], [626, 'entailment'], [627, 'entailment'], [628, 'entailment'], [629, 'entailment'], [630, 'entailment'], [631, 'entailment'], [632, 'entailment'], [633, 'entailment'], [634, 'entailment'], [635, 'entailment'], [636, 'entailment'], [637, 'entailment'], [638, 'entailment'], [639, 'entailment'], [640, 'entailment'], [641, 'entailment'], [642, 'entailment'], [643, 'entailment'], [644, 'entailment'], [645, 'entailment'], [646, 'entailment'], [647, 'entailment'], [648, 'entailment'], [649, 'entailment'], [650, 'entailment'], [651, 'entailment'], [652, 'entailment'], [653, 'entailment'], [654, 'entailment'], [655, 'entailment'], [656, 'entailment'], [657, 'entailment'], [658, 'entailment'], [659, 'entailment'], [660, 'entailment'], [661, 'entailment'], [662, 'entailment'], [663, 'entailment'], [664, 'entailment'], [665, 'entailment'], [666, 'entailment'], [667, 'entailment'], [668, 'entailment'], [669, 'entailment'], [670, 'entailment'], [671, 'entailment'], [672, 'entailment'], [673, 'entailment'], [674, 'entailment'], [675, 'entailment'], [676, 'entailment'], [677, 'entailment'], [678, 'entailment'], [679, 'entailment'], [680, 'entailment'], [681, 'entailment'], [682, 'entailment'], [683, 'entailment'], [684, 'entailment'], [685, 'entailment'], [686, 'entailment'], [687, 'entailment'], [688, 'entailment'], [689, 'entailment'], [690, 'entailment'], [691, 'entailment'], [692, 'entailment'], [693, 'entailment'], [694, 'entailment'], [695, 'entailment'], [696, 'entailment'], [697, 'entailment'], [698, 'entailment'], [699, 'entailment'], [700, 'entailment'], [701, 'entailment'], [702, 'entailment'], [703, 'entailment'], [704, 'entailment'], [705, 'entailment'], [706, 'entailment'], [707, 'entailment'], [708, 'entailment'], [709, 'entailment'], [710, 'entailment'], [711, 'entailment'], [712, 'entailment'], [713, 'entailment'], [714, 'entailment'], [715, 'entailment'], [716, 'entailment'], [717, 'entailment'], [718, 'entailment'], [719, 'entailment'], [720, 'entailment'], [721, 'entailment'], [722, 'entailment'], [723, 'entailment'], [724, 'entailment'], [725, 'entailment'], [726, 'entailment'], [727, 'entailment'], [728, 'entailment'], [729, 'entailment'], [730, 'entailment'], [731, 'entailment'], [732, 'entailment'], [733, 'entailment'], [734, 'entailment'], [735, 'entailment'], [736, 'entailment'], [737, 'entailment'], [738, 'entailment'], [739, 'entailment'], [740, 'entailment'], [741, 'entailment'], [742, 'entailment'], [743, 'entailment'], [744, 'entailment'], [745, 'entailment'], [746, 'entailment'], [747, 'entailment'], [748, 'entailment'], [749, 'entailment'], [750, 'entailment'], [751, 'entailment'], [752, 'entailment'], [753, 'entailment'], [754, 'entailment'], [755, 'entailment'], [756, 'entailment'], [757, 'entailment'], [758, 'entailment'], [759, 'entailment'], [760, 'entailment'], [761, 'entailment'], [762, 'entailment'], [763, 'entailment'], [764, 'entailment'], [765, 'entailment'], [766, 'entailment'], [767, 'entailment'], [768, 'entailment'], [769, 'entailment'], [770, 'entailment'], [771, 'entailment'], [772, 'entailment'], [773, 'entailment'], [774, 'entailment'], [775, 'entailment'], [776, 'entailment'], [777, 'entailment'], [778, 'entailment'], [779, 'entailment'], [780, 'entailment'], [781, 'entailment'], [782, 'entailment'], [783, 'entailment'], [784, 'entailment'], [785, 'entailment'], [786, 'entailment'], [787, 'entailment'], [788, 'entailment'], [789, 'entailment'], [790, 'entailment'], [791, 'entailment'], [792, 'entailment'], [793, 'entailment'], [794, 'entailment'], [795, 'entailment'], [796, 'entailment'], [797, 'entailment'], [798, 'entailment'], [799, 'entailment'], [800, 'entailment'], [801, 'entailment'], [802, 'entailment'], [803, 'entailment'], [804, 'entailment'], [805, 'entailment'], [806, 'entailment'], [807, 'entailment'], [808, 'entailment'], [809, 'entailment'], [810, 'entailment'], [811, 'entailment'], [812, 'entailment'], [813, 'entailment'], [814, 'entailment'], [815, 'entailment'], [816, 'entailment'], [817, 'entailment'], [818, 'entailment'], [819, 'entailment'], [820, 'entailment'], [821, 'entailment'], [822, 'entailment'], [823, 'entailment'], [824, 'entailment'], [825, 'entailment'], [826, 'entailment'], [827, 'entailment'], [828, 'entailment'], [829, 'entailment'], [830, 'entailment'], [831, 'entailment'], [832, 'entailment'], [833, 'entailment'], [834, 'entailment'], [835, 'entailment'], [836, 'entailment'], [837, 'entailment'], [838, 'entailment'], [839, 'entailment'], [840, 'entailment'], [841, 'entailment'], [842, 'entailment'], [843, 'entailment'], [844, 'entailment'], [845, 'entailment'], [846, 'entailment'], [847, 'entailment'], [848, 'entailment'], [849, 'entailment'], [850, 'entailment'], [851, 'entailment'], [852, 'entailment'], [853, 'entailment'], [854, 'entailment'], [855, 'entailment'], [856, 'entailment'], [857, 'entailment'], [858, 'entailment'], [859, 'entailment'], [860, 'entailment'], [861, 'entailment'], [862, 'entailment'], [863, 'entailment'], [864, 'entailment'], [865, 'entailment'], [866, 'entailment'], [867, 'entailment'], [868, 'entailment'], [869, 'entailment'], [870, 'entailment'], [871, 'entailment'], [872, 'entailment'], [873, 'entailment'], [874, 'entailment'], [875, 'entailment'], [876, 'entailment'], [877, 'entailment'], [878, 'entailment'], [879, 'entailment'], [880, 'entailment'], [881, 'entailment'], [882, 'entailment'], [883, 'entailment'], [884, 'entailment'], [885, 'entailment'], [886, 'entailment'], [887, 'entailment'], [888, 'entailment'], [889, 'entailment'], [890, 'entailment'], [891, 'entailment'], [892, 'entailment'], [893, 'entailment'], [894, 'entailment'], [895, 'entailment'], [896, 'entailment'], [897, 'entailment'], [898, 'entailment'], [899, 'entailment'], [900, 'entailment'], [901, 'entailment'], [902, 'entailment'], [903, 'entailment'], [904, 'entailment'], [905, 'entailment'], [906, 'entailment'], [907, 'entailment'], [908, 'entailment'], [909, 'entailment'], [910, 'entailment'], [911, 'entailment'], [912, 'entailment'], [913, 'entailment'], [914, 'entailment'], [915, 'entailment'], [916, 'entailment'], [917, 'entailment'], [918, 'entailment'], [919, 'entailment'], [920, 'entailment'], [921, 'entailment'], [922, 'entailment'], [923, 'entailment'], [924, 'entailment'], [925, 'entailment'], [926, 'entailment'], [927, 'entailment'], [928, 'entailment'], [929, 'entailment'], [930, 'entailment'], [931, 'entailment'], [932, 'entailment'], [933, 'entailment'], [934, 'entailment'], [935, 'entailment'], [936, 'entailment'], [937, 'entailment'], [938, 'entailment'], [939, 'entailment'], [940, 'entailment'], [941, 'entailment'], [942, 'entailment'], [943, 'entailment'], [944, 'entailment'], [945, 'entailment'], [946, 'entailment'], [947, 'entailment'], [948, 'entailment'], [949, 'entailment'], [950, 'entailment'], [951, 'entailment'], [952, 'entailment'], [953, 'entailment'], [954, 'entailment'], [955, 'entailment'], [956, 'entailment'], [957, 'entailment'], [958, 'entailment'], [959, 'entailment'], [960, 'entailment'], [961, 'entailment'], [962, 'entailment'], [963, 'entailment'], [964, 'entailment'], [965, 'entailment'], [966, 'entailment'], [967, 'entailment'], [968, 'entailment'], [969, 'entailment'], [970, 'entailment'], [971, 'entailment'], [972, 'entailment'], [973, 'entailment'], [974, 'entailment'], [975, 'entailment'], [976, 'entailment'], [977, 'entailment'], [978, 'entailment'], [979, 'entailment'], [980, 'entailment'], [981, 'entailment'], [982, 'entailment'], [983, 'entailment'], [984, 'entailment'], [985, 'entailment'], [986, 'entailment'], [987, 'entailment'], [988, 'entailment'], [989, 'entailment'], [990, 'entailment'], [991, 'entailment'], [992, 'entailment'], [993, 'entailment'], [994, 'entailment'], [995, 'entailment'], [996, 'entailment'], [997, 'entailment'], [998, 'entailment'], [999, 'entailment'], [1000, 'entailment'], [1001, 'entailment'], [1002, 'entailment'], [1003, 'entailment'], [1004, 'entailment'], [1005, 'entailment'], [1006, 'entailment'], [1007, 'entailment'], [1008, 'entailment'], [1009, 'entailment'], [1010, 'entailment'], [1011, 'entailment'], [1012, 'entailment'], [1013, 'entailment'], [1014, 'entailment'], [1015, 'entailment'], [1016, 'entailment'], [1017, 'entailment'], [1018, 'entailment'], [1019, 'entailment'], [1020, 'entailment'], [1021, 'entailment'], [1022, 'entailment'], [1023, 'entailment'], [1024, 'entailment'], [1025, 'entailment'], [1026, 'entailment'], [1027, 'entailment'], [1028, 'entailment'], [1029, 'entailment'], [1030, 'entailment'], [1031, 'entailment'], [1032, 'entailment'], [1033, 'entailment'], [1034, 'entailment'], [1035, 'entailment'], [1036, 'entailment'], [1037, 'entailment'], [1038, 'entailment'], [1039, 'entailment'], [1040, 'entailment'], [1041, 'entailment'], [1042, 'entailment'], [1043, 'entailment'], [1044, 'entailment'], [1045, 'entailment'], [1046, 'entailment'], [1047, 'entailment'], [1048, 'entailment'], [1049, 'entailment'], [1050, 'entailment'], [1051, 'entailment'], [1052, 'entailment'], [1053, 'entailment'], [1054, 'entailment'], [1055, 'entailment'], [1056, 'entailment'], [1057, 'entailment'], [1058, 'entailment'], [1059, 'entailment'], [1060, 'entailment'], [1061, 'entailment'], [1062, 'entailment'], [1063, 'entailment'], [1064, 'entailment'], [1065, 'entailment'], [1066, 'entailment'], [1067, 'entailment'], [1068, 'entailment'], [1069, 'entailment'], [1070, 'entailment'], [1071, 'entailment'], [1072, 'entailment'], [1073, 'entailment'], [1074, 'entailment'], [1075, 'entailment'], [1076, 'entailment'], [1077, 'entailment'], [1078, 'entailment'], [1079, 'entailment'], [1080, 'entailment'], [1081, 'entailment'], [1082, 'entailment'], [1083, 'entailment'], [1084, 'entailment'], [1085, 'entailment'], [1086, 'entailment'], [1087, 'entailment'], [1088, 'entailment'], [1089, 'entailment'], [1090, 'entailment'], [1091, 'entailment'], [1092, 'entailment'], [1093, 'entailment'], [1094, 'entailment'], [1095, 'entailment'], [1096, 'entailment'], [1097, 'entailment'], [1098, 'entailment'], [1099, 'entailment'], [1100, 'entailment'], [1101, 'entailment'], [1102, 'entailment'], [1103, 'entailment'], [1104, 'entailment'], [1105, 'entailment'], [1106, 'entailment'], [1107, 'entailment'], [1108, 'entailment'], [1109, 'entailment'], [1110, 'entailment'], [1111, 'entailment'], [1112, 'entailment'], [1113, 'entailment'], [1114, 'entailment'], [1115, 'entailment'], [1116, 'entailment'], [1117, 'entailment'], [1118, 'entailment'], [1119, 'entailment'], [1120, 'entailment'], [1121, 'entailment'], [1122, 'entailment'], [1123, 'entailment'], [1124, 'entailment'], [1125, 'entailment'], [1126, 'entailment'], [1127, 'entailment'], [1128, 'entailment'], [1129, 'entailment'], [1130, 'entailment'], [1131, 'entailment'], [1132, 'entailment'], [1133, 'entailment'], [1134, 'entailment'], [1135, 'entailment'], [1136, 'entailment'], [1137, 'entailment'], [1138, 'entailment'], [1139, 'entailment'], [1140, 'entailment'], [1141, 'entailment'], [1142, 'entailment'], [1143, 'entailment'], [1144, 'entailment'], [1145, 'entailment'], [1146, 'entailment'], [1147, 'entailment'], [1148, 'entailment'], [1149, 'entailment'], [1150, 'entailment'], [1151, 'entailment'], [1152, 'entailment'], [1153, 'entailment'], [1154, 'entailment'], [1155, 'entailment'], [1156, 'entailment'], [1157, 'entailment'], [1158, 'entailment'], [1159, 'entailment'], [1160, 'entailment'], [1161, 'entailment'], [1162, 'entailment'], [1163, 'entailment'], [1164, 'entailment'], [1165, 'entailment'], [1166, 'entailment'], [1167, 'entailment'], [1168, 'entailment'], [1169, 'entailment'], [1170, 'entailment'], [1171, 'entailment'], [1172, 'entailment'], [1173, 'entailment'], [1174, 'entailment'], [1175, 'entailment'], [1176, 'entailment'], [1177, 'entailment'], [1178, 'entailment'], [1179, 'entailment'], [1180, 'entailment'], [1181, 'entailment'], [1182, 'entailment'], [1183, 'entailment'], [1184, 'entailment'], [1185, 'entailment'], [1186, 'entailment'], [1187, 'entailment'], [1188, 'entailment'], [1189, 'entailment'], [1190, 'entailment'], [1191, 'entailment'], [1192, 'entailment'], [1193, 'entailment'], [1194, 'entailment'], [1195, 'entailment'], [1196, 'entailment'], [1197, 'entailment'], [1198, 'entailment'], [1199, 'entailment'], [1200, 'entailment'], [1201, 'entailment'], [1202, 'entailment'], [1203, 'entailment'], [1204, 'entailment'], [1205, 'entailment'], [1206, 'entailment'], [1207, 'entailment'], [1208, 'entailment'], [1209, 'entailment'], [1210, 'entailment'], [1211, 'entailment'], [1212, 'entailment'], [1213, 'entailment'], [1214, 'entailment'], [1215, 'entailment'], [1216, 'entailment'], [1217, 'entailment'], [1218, 'entailment'], [1219, 'entailment'], [1220, 'entailment'], [1221, 'entailment'], [1222, 'entailment'], [1223, 'entailment'], [1224, 'entailment'], [1225, 'entailment'], [1226, 'entailment'], [1227, 'entailment'], [1228, 'entailment'], [1229, 'entailment'], [1230, 'entailment'], [1231, 'entailment'], [1232, 'entailment'], [1233, 'entailment'], [1234, 'entailment'], [1235, 'entailment'], [1236, 'entailment'], [1237, 'entailment'], [1238, 'entailment'], [1239, 'entailment'], [1240, 'entailment'], [1241, 'entailment'], [1242, 'entailment'], [1243, 'entailment'], [1244, 'entailment'], [1245, 'entailment'], [1246, 'entailment'], [1247, 'entailment'], [1248, 'entailment'], [1249, 'entailment'], [1250, 'entailment'], [1251, 'entailment'], [1252, 'entailment'], [1253, 'entailment'], [1254, 'entailment'], [1255, 'entailment'], [1256, 'entailment'], [1257, 'entailment'], [1258, 'entailment'], [1259, 'entailment'], [1260, 'entailment'], [1261, 'entailment'], [1262, 'entailment'], [1263, 'entailment'], [1264, 'entailment'], [1265, 'entailment'], [1266, 'entailment'], [1267, 'entailment'], [1268, 'entailment'], [1269, 'entailment'], [1270, 'entailment'], [1271, 'entailment'], [1272, 'entailment'], [1273, 'entailment'], [1274, 'entailment'], [1275, 'entailment'], [1276, 'entailment'], [1277, 'entailment'], [1278, 'entailment'], [1279, 'entailment'], [1280, 'entailment'], [1281, 'entailment'], [1282, 'entailment'], [1283, 'entailment'], [1284, 'entailment'], [1285, 'entailment'], [1286, 'entailment'], [1287, 'entailment'], [1288, 'entailment'], [1289, 'entailment'], [1290, 'entailment'], [1291, 'entailment'], [1292, 'entailment'], [1293, 'entailment'], [1294, 'entailment'], [1295, 'entailment'], [1296, 'entailment'], [1297, 'entailment'], [1298, 'entailment'], [1299, 'entailment'], [1300, 'entailment'], [1301, 'entailment'], [1302, 'entailment'], [1303, 'entailment'], [1304, 'entailment'], [1305, 'entailment'], [1306, 'entailment'], [1307, 'entailment'], [1308, 'entailment'], [1309, 'entailment'], [1310, 'entailment'], [1311, 'entailment'], [1312, 'entailment'], [1313, 'entailment'], [1314, 'entailment'], [1315, 'entailment'], [1316, 'entailment'], [1317, 'entailment'], [1318, 'entailment'], [1319, 'entailment'], [1320, 'entailment'], [1321, 'entailment'], [1322, 'entailment'], [1323, 'entailment'], [1324, 'entailment'], [1325, 'entailment'], [1326, 'entailment'], [1327, 'entailment'], [1328, 'entailment'], [1329, 'entailment'], [1330, 'entailment'], [1331, 'entailment'], [1332, 'entailment'], [1333, 'entailment'], [1334, 'entailment'], [1335, 'entailment'], [1336, 'entailment'], [1337, 'entailment'], [1338, 'entailment'], [1339, 'entailment'], [1340, 'entailment'], [1341, 'entailment'], [1342, 'entailment'], [1343, 'entailment'], [1344, 'entailment'], [1345, 'entailment'], [1346, 'entailment'], [1347, 'entailment'], [1348, 'entailment'], [1349, 'entailment'], [1350, 'entailment'], [1351, 'entailment'], [1352, 'entailment'], [1353, 'entailment'], [1354, 'entailment'], [1355, 'entailment'], [1356, 'entailment'], [1357, 'entailment'], [1358, 'entailment'], [1359, 'entailment'], [1360, 'entailment'], [1361, 'entailment'], [1362, 'entailment'], [1363, 'entailment'], [1364, 'entailment'], [1365, 'entailment'], [1366, 'entailment'], [1367, 'entailment'], [1368, 'entailment'], [1369, 'entailment'], [1370, 'entailment'], [1371, 'entailment'], [1372, 'entailment'], [1373, 'entailment'], [1374, 'entailment'], [1375, 'entailment'], [1376, 'entailment'], [1377, 'entailment'], [1378, 'entailment'], [1379, 'entailment'], [1380, 'entailment'], [1381, 'entailment'], [1382, 'entailment'], [1383, 'entailment'], [1384, 'entailment'], [1385, 'entailment'], [1386, 'entailment'], [1387, 'entailment'], [1388, 'entailment'], [1389, 'entailment'], [1390, 'entailment'], [1391, 'entailment'], [1392, 'entailment'], [1393, 'entailment'], [1394, 'entailment'], [1395, 'entailment'], [1396, 'entailment'], [1397, 'entailment'], [1398, 'entailment'], [1399, 'entailment'], [1400, 'entailment'], [1401, 'entailment'], [1402, 'entailment'], [1403, 'entailment'], [1404, 'entailment'], [1405, 'entailment'], [1406, 'entailment'], [1407, 'entailment'], [1408, 'entailment'], [1409, 'entailment'], [1410, 'entailment'], [1411, 'entailment'], [1412, 'entailment'], [1413, 'entailment'], [1414, 'entailment'], [1415, 'entailment'], [1416, 'entailment'], [1417, 'entailment'], [1418, 'entailment'], [1419, 'entailment'], [1420, 'entailment'], [1421, 'entailment'], [1422, 'entailment'], [1423, 'entailment'], [1424, 'entailment'], [1425, 'entailment'], [1426, 'entailment'], [1427, 'entailment'], [1428, 'entailment'], [1429, 'entailment'], [1430, 'entailment'], [1431, 'entailment'], [1432, 'entailment'], [1433, 'entailment'], [1434, 'entailment'], [1435, 'entailment'], [1436, 'entailment'], [1437, 'entailment'], [1438, 'entailment'], [1439, 'entailment'], [1440, 'entailment'], [1441, 'entailment'], [1442, 'entailment'], [1443, 'entailment'], [1444, 'entailment'], [1445, 'entailment'], [1446, 'entailment'], [1447, 'entailment'], [1448, 'entailment'], [1449, 'entailment'], [1450, 'entailment'], [1451, 'entailment'], [1452, 'entailment'], [1453, 'entailment'], [1454, 'entailment'], [1455, 'entailment'], [1456, 'entailment'], [1457, 'entailment'], [1458, 'entailment'], [1459, 'entailment'], [1460, 'entailment'], [1461, 'entailment'], [1462, 'entailment'], [1463, 'entailment'], [1464, 'entailment'], [1465, 'entailment'], [1466, 'entailment'], [1467, 'entailment'], [1468, 'entailment'], [1469, 'entailment'], [1470, 'entailment'], [1471, 'entailment'], [1472, 'entailment'], [1473, 'entailment'], [1474, 'entailment'], [1475, 'entailment'], [1476, 'entailment'], [1477, 'entailment'], [1478, 'entailment'], [1479, 'entailment'], [1480, 'entailment'], [1481, 'entailment'], [1482, 'entailment'], [1483, 'entailment'], [1484, 'entailment'], [1485, 'entailment'], [1486, 'entailment'], [1487, 'entailment'], [1488, 'entailment'], [1489, 'entailment'], [1490, 'entailment'], [1491, 'entailment'], [1492, 'entailment'], [1493, 'entailment'], [1494, 'entailment'], [1495, 'entailment'], [1496, 'entailment'], [1497, 'entailment'], [1498, 'entailment'], [1499, 'entailment'], [1500, 'entailment'], [1501, 'entailment'], [1502, 'entailment'], [1503, 'entailment'], [1504, 'entailment'], [1505, 'entailment'], [1506, 'entailment'], [1507, 'entailment'], [1508, 'entailment'], [1509, 'entailment'], [1510, 'entailment'], [1511, 'entailment'], [1512, 'entailment'], [1513, 'entailment'], [1514, 'entailment'], [1515, 'entailment'], [1516, 'entailment'], [1517, 'entailment'], [1518, 'entailment'], [1519, 'entailment'], [1520, 'entailment'], [1521, 'entailment'], [1522, 'entailment'], [1523, 'entailment'], [1524, 'entailment'], [1525, 'entailment'], [1526, 'entailment'], [1527, 'entailment'], [1528, 'entailment'], [1529, 'entailment'], [1530, 'entailment'], [1531, 'entailment'], [1532, 'entailment'], [1533, 'entailment'], [1534, 'entailment'], [1535, 'entailment'], [1536, 'entailment'], [1537, 'entailment'], [1538, 'entailment'], [1539, 'entailment'], [1540, 'entailment'], [1541, 'entailment'], [1542, 'entailment'], [1543, 'entailment'], [1544, 'entailment'], [1545, 'entailment'], [1546, 'entailment'], [1547, 'entailment'], [1548, 'entailment'], [1549, 'entailment'], [1550, 'entailment'], [1551, 'entailment'], [1552, 'entailment'], [1553, 'entailment'], [1554, 'entailment'], [1555, 'entailment'], [1556, 'entailment'], [1557, 'entailment'], [1558, 'entailment'], [1559, 'entailment'], [1560, 'entailment'], [1561, 'entailment'], [1562, 'entailment'], [1563, 'entailment'], [1564, 'entailment'], [1565, 'entailment'], [1566, 'entailment'], [1567, 'entailment'], [1568, 'entailment'], [1569, 'entailment'], [1570, 'entailment'], [1571, 'entailment'], [1572, 'entailment'], [1573, 'entailment'], [1574, 'entailment'], [1575, 'entailment'], [1576, 'entailment'], [1577, 'entailment'], [1578, 'entailment'], [1579, 'entailment'], [1580, 'entailment'], [1581, 'entailment'], [1582, 'entailment'], [1583, 'entailment'], [1584, 'entailment'], [1585, 'entailment'], [1586, 'entailment'], [1587, 'entailment'], [1588, 'entailment'], [1589, 'entailment'], [1590, 'entailment'], [1591, 'entailment'], [1592, 'entailment'], [1593, 'entailment'], [1594, 'entailment'], [1595, 'entailment'], [1596, 'entailment'], [1597, 'entailment'], [1598, 'entailment'], [1599, 'entailment'], [1600, 'entailment'], [1601, 'entailment'], [1602, 'entailment'], [1603, 'entailment'], [1604, 'entailment'], [1605, 'entailment'], [1606, 'entailment'], [1607, 'entailment'], [1608, 'entailment'], [1609, 'entailment'], [1610, 'entailment'], [1611, 'entailment'], [1612, 'entailment'], [1613, 'entailment'], [1614, 'entailment'], [1615, 'entailment'], [1616, 'entailment'], [1617, 'entailment'], [1618, 'entailment'], [1619, 'entailment'], [1620, 'entailment'], [1621, 'entailment'], [1622, 'entailment'], [1623, 'entailment'], [1624, 'entailment'], [1625, 'entailment'], [1626, 'entailment'], [1627, 'entailment'], [1628, 'entailment'], [1629, 'entailment'], [1630, 'entailment'], [1631, 'entailment'], [1632, 'entailment'], [1633, 'entailment'], [1634, 'entailment'], [1635, 'entailment'], [1636, 'entailment'], [1637, 'entailment'], [1638, 'entailment'], [1639, 'entailment'], [1640, 'entailment'], [1641, 'entailment'], [1642, 'entailment'], [1643, 'entailment'], [1644, 'entailment'], [1645, 'entailment'], [1646, 'entailment'], [1647, 'entailment'], [1648, 'entailment'], [1649, 'entailment'], [1650, 'entailment'], [1651, 'entailment'], [1652, 'entailment'], [1653, 'entailment'], [1654, 'entailment'], [1655, 'entailment'], [1656, 'entailment'], [1657, 'entailment'], [1658, 'entailment'], [1659, 'entailment'], [1660, 'entailment'], [1661, 'entailment'], [1662, 'entailment'], [1663, 'entailment'], [1664, 'entailment'], [1665, 'entailment']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(answer, columns=['index', 'label'])\n",
        "\n",
        "df.to_csv('./result/submission-koBERT-lm.csv', index=False)"
      ],
      "metadata": {
        "id": "73x0wi8zJMfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc289d72-dc42-4546-9272-97f1a99a8efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      index       label\n",
            "0         0  entailment\n",
            "1         1  entailment\n",
            "2         2  entailment\n",
            "3         3  entailment\n",
            "4         4  entailment\n",
            "...     ...         ...\n",
            "1661   1661  entailment\n",
            "1662   1662  entailment\n",
            "1663   1663  entailment\n",
            "1664   1664  entailment\n",
            "1665   1665  entailment\n",
            "\n",
            "[1666 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Uo-7SmOL5bIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7Ws8jtOT5bA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DgcWbCryJMcX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}